---
title: "p8105_hw3_hj2660"
author: "Hyun Jin Jung"
date: "2023-10-14"
output: github_document
---
```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)
library(tidyr)
library(leaflet)

library(p8105.datasets)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

First, load the data from the `p8105.datasets`
```{r}
data(instacart)
```


The dataset includes `r nrow(instacart)` observations and `r ncol(instacart)` variables. Some of the key variables in the dataset include `order_id`, `product_id`, `user_id`, `aisle_id`, `department_id`, `product_name`, `order_dow`, and `order_hour_of_day`. One illustrative example is `r instacart[1,]$product_name` (Product ID: `r instacart[1,]$product_id`) found in the `r instacart[1,]$aisle` aisle in `r instacart[1,]$department` department. This product was purchased by the User ID: `r instacart[1,]$user_id` on the `r instacart[1,]$order_dow`th day of the week at `r instacart[1,]$order_hour_of_day`AM. It has been `r instacart[1,]$days_since_prior_order` days since prior order.


- How many aisles are there, and which aisles are the most items ordered from?

```{r}
instacart_aisle = instacart |>
  group_by(aisle) |>
  summarize(n_orders = n()) |>
  arrange(desc(n_orders))
```

There are `r nrow(instacart_aisle)` aisles. The aisle with the most items ordered is "`r instacart_aisle$aisle[1]`" with `r instacart_aisle$n_orders[1]` items.

- Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r}
instacart |>
  count(aisle) |>
  filter(n > 10000) |>
  mutate(aisle = fct_reorder(aisle, n)) |>
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

- Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.
```{r}
instacart |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |>
  count(product_name) |>
  mutate(rank = min_rank(desc(n))) |>
  filter(rank < 4) |>
  arrange(desc(n)) |>
  knitr::kable()
```

- Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).
```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour) |>
  knitr::kable(digits = 2)
```


## Problem 2

First, import dataset.
```{r}
data("brfss_smart2010")
```

Do some data cleaning, with a specific focus on the `Overall Health` topic. Include only responses that are ordered from `Poor` to `Excellent`.
```{r}
brfss_df = brfss_smart2010 |>
  janitor::clean_names() |>
  filter(topic == "Overall Health" &
         response %in% c("Excellent", "Very good", "Good", "Fair", "Poor"))

ordered_brfss = brfss_df[order(factor(brfss_df$response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))),]
```


```{r}
states_2002 =
  ordered_brfss |>
  filter(year == "2002") |> 
  group_by(locationabbr) |>
  summarize(locations = n_distinct(locationdesc)) |>
  filter(locations >= 7)
```
In 2002, there are `r nrow(states_2002)` states observed at 7 or more locations.


```{r}
states_2010 =
  ordered_brfss |>
  filter(year == "2010") |> 
  group_by(locationabbr) |>
  summarize(locations = n_distinct(locationdesc)) |>
  filter(locations >= 7)
```
In 2010, there are `r nrow(states_2010)` states observed at 7 or more locations.

Construct a dataset that only has "Excellent" responses and contains `year`, `state`, and average of the `data_value`. Then, make a plot.
```{r}
excl_brfss =
  ordered_brfss |>
  filter(response == "Excellent") |>
  group_by(year, locationabbr) |>
  mutate(avg_data = mean(data_value)) |>
  select(year, locationabbr, avg_data)

#Create the plot
ggplot(excl_brfss, aes(x = year,
                       y = avg_data,
                       group = locationabbr,
                       color = locationabbr)) +
  geom_line(size = 1) + 
  labs(title = "Average Data Value Over within a State (Excellent)",
       x = "Year",
       y = "Average Data Value",
       color = "State") +
  theme_minimal()
```


Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State
```{r}
ny_df =
  ordered_brfss |>
  filter(locationabbr == "NY", year %in% c(2006, 2010))

#Create a two-panel plot
ggplot(ny_df, aes(x = data_value, fill = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent")))) +
  geom_histogram(binwidth = 0.5) +
  facet_wrap(~year, nrow = 1) +
  labs(
    title = "Distribution of Data Value by Response in New York State (2006 and 2010)",
    x = "Data Value",
    y = "Frequency",
    fill = "Response"
  ) 
```
among locations?
```{r}
ny_df = ny_df |>
  mutate(geo_location = gsub("[()]", "", geo_location)) |>
  separate(geo_location, into = c("latitude", "longitude"), sep = ", ") |>
  mutate(latitude = as.numeric(latitude), longitude = as.numeric(longitude)) |>
  filter(locationabbr == "NY", year %in% c(2006, 2010)) 


ny_df |>
  leaflet() |>
  addProviderTiles(providers$CartoDB.Positron) |>
  addCircleMarkers(lat = ~latitude, lng = ~longitude, radius = 0.5)

```

